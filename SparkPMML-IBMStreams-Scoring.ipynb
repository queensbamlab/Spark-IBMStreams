{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# IBM Streams Spark PMML scoring sample application\n",
    "\n",
    "This sample demonstrates creating a Streams Python application to perform scoring with a Spark PMML model and viewing the results.\n",
    "\n",
    "\n",
    "<ol>\n",
    "    <li><a href=\"#setup\">Setup</a>\n",
    "        <ul style=\"list-style-type:none;\">\n",
    "            <li>1.1. <a href=\"#setupStreams\">Connection to Streams Instance</a></li>\n",
    "            <li>1.2. <a href=\"#setupPackages\">Install additional packages</a></li>\n",
    "            <li>1.3. <a href=\"#setupDataModel\">Add data and model</a></li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li><a href=\"#create\">Create the application</a>\n",
    "        <ul style=\"list-style-type:none;\">\n",
    "            <li>2.1. <a href=\"#defineInput\">Define Data Input</a></li>\n",
    "            <li>2.2. <a href=\"#analyzeData\">Analyze Data (ML scoring)</a>\n",
    "                <ul style=\"list-style-type:none;\">\n",
    "                    <li>2.2.1. <a href=\"#prepareData\">Prepare Data for scoring</a></li>\n",
    "                    <li>2.2.2. <a href=\"#scoreData\">Score Data</a></li>\n",
    "                </ul>\n",
    "            </li>\n",
    "            <li>2.3 <a href=\"#defineOutput\">Define Data Output</a></li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li><a href=\"#submit\">Submit the application</a></li>\n",
    "    <li><a href=\"#view\">Connect to the running application to view data</a></li>\n",
    "    <li><a href=\"#cancel\">Stop the application</a></li>\n",
    "</ol>\n",
    "\n",
    "<a name=\"overview\"></a>\n",
    "\n",
    "# Overview\n",
    "\n",
    "**About the sample**\n",
    "\n",
    "This sample application adapt the model of the heart disease patients' health data to demonstrate the process of developing Spark-based PMML model and then score it in IBM Streams. \n",
    "\n",
    "__Creating the model__\n",
    "The ML scenario is a simple process of converting Apache Spark ML pipelines to PMML.\n",
    "Details available via: https://openscoring.io/blog/2018/07/09/converting_sparkml_pipeline_pmml/\n",
    "\n",
    "\n",
    "**How it works**\n",
    "\n",
    "This sample build around the following previous samples: Basic Streams Sample and IBM Streams PMML scoring sample application. The main addition here is the introduction of Spark for in-memory processing.\n",
    "\n",
    "<img src=\"https://developer.ibm.com/streamsdev/wp-content/uploads/sites/15/2019/04/how-it-works.jpg\" alt=\"How it works\">\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "### Documentation & Information links\n",
    "\n",
    "- [Streams Python development guide](https://ibmstreams.github.io/streamsx.documentation/docs/latest/python/)\n",
    "- [streamsx.topology Python API](https://streamsxtopology.readthedocs.io/)\n",
    "- [streamsx.pmml Python API](https://streamsxpmml.readthedocs.io/)\n",
    "- [PMML at Wikipedia](https://en.wikipedia.org/wiki/Predictive_Model_Markup_Language)\n",
    "- [PMML specification at Data Mining Group](http://dmg.org/pmml/v4-3/GeneralStructure.html)\n",
    "- https://github.com/jpmml/pyspark2pmml\n",
    "- https://github.com/jpmml/jpmml-sparkml\n",
    "- https://github.com/pmservice/wml-sample-models/tree/master/spark/import-pmml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a id=\"setup\"></a>\n",
    "\n",
    "# 1. Setup\n",
    "\n",
    "  \n",
    "  \n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>What do we need to set up for our sample application?</b>  \n",
    "<ul>    \n",
    "<li>A connection to a running <b>IBM Streams instance</b> <br> \n",
    "   This notebook describes using a Streams instance in IBM Cloud Streaming Service.</li>\n",
    "<li><b>streamsx.topology</b> - the Python package providing the IBM Streams standard/basic function set</li>\n",
    "<li><b>streamsx.pmml</b> - the Python package providing the IBM Streams PMML scoring functionality</li>\n",
    "<li><b>pyspark</b> - Spark Python API that exposes the Spark programming model to Python <br> \n",
    "    This library will not be required if the model is being developed in Watson Studio with Spark and Python session.</li>\n",
    "<li><b>pyspark2pmml</b> - Python library for converting Apache Spark ML pipelines to PMML </li>    \n",
    "<li><b>Data set</b> Iris dataset or any dataset that can be simulated to \"stream\" through the application</li>\n",
    "<li><b>Trained PMML model</b> that will predict the Species of the streaming instances of the Iris data </li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "<a id=\"setupStreams\"></a>\n",
    "\n",
    "### 1.1 Add credentials for the IBM Streams service\n",
    "\n",
    "In order to submit a Streams application you need to provide the name of the Streams instance.\n",
    "\n",
    "1. From the navigation menu, click **My instances**.\n",
    "2. Click the **Provisioned Instances** tab.\n",
    "3. Update the value of `streams_instance_name` in the cell below according to your Streams instance name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Paste snippet from development guide\n",
    "from streamsx.topology.context import ConfigParams\n",
    "from streamsx.topology import context\n",
    "import json\n",
    "import getpass\n",
    "        \n",
    "        \n",
    "service_cfg  = {}\n",
    "        \n",
    "SA_credentials=getpass.getpass('Streaming Analytics credentials:')\n",
    "service_cfg[ConfigParams.SERVICE_DEFINITION] = json.loads(SA_credentials)\n",
    "\n",
    "def submit_topology(topo):\n",
    "    global service_cfg\n",
    "    service_cfg[context.ConfigParams.SSL_VERIFY] = False\n",
    "\n",
    "    # This specifies how the application will be deployed\n",
    "\n",
    "    contextType = context.ContextTypes.STREAMING_ANALYTICS_SERVICE\n",
    "\n",
    "    return context.submit (contextType, topo, config = service_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"setupPackages\"></a>\n",
    "\n",
    "## 1.2 Optional: Upgrade streamsx Python packages\n",
    "\n",
    "As described in the [overview](#overview), we need the Python packages providing the Streams functionality to create streaming applications using Python, __streamsx__ and __streamsx.pmml__, __pyspark__, __pyspark2pmml__. These packages should be installed on the notebook. <br>\n",
    "Uncomment and run the cell below if you want to upgrade to the latest version of the streamsx.pmml package.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --user --upgrade streamsx.pmml\n",
    "#!pip install pyspark==2.3.3\n",
    "# !pip install pyspark2pmml\n",
    "!wget https://raw.githubusercontent.com/hisah/dataset/master/jpmml-sparkml-executable-1.4.11.jar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The python packages will be installed in the top of user path.<br/>\n",
    "If you have problem to get the latest version of python packages you can set the order of python packages manually to user path.<br/>\n",
    "you can find the user path with this command:<br/>\n",
    "`\n",
    "import sys\n",
    "for e in sys.path:\n",
    "    print(e)\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#sys.path.insert(0, '/home/wsuser/.local/lib/python3.6/site-packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the installed versions of both packages\n",
    "import streamsx.topology.context\n",
    "import streamsx.pmml as pmml\n",
    "print(\"INFO: streamsx package version: \" + streamsx.topology.context.__version__)\n",
    "print(\"INFO: streamsx.pmml package version: \" + pmml.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "from pyspark import SparkConf, SparkContext\n",
    "conf = SparkConf().setMaster(\"local\").setAppName(\"SparkKMeans\").set(\"spark.jars\", \"jpmml-sparkml-executable-1.4.11.jar\")\n",
    "sc = SparkContext(conf = conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import data\n",
    "!wget https://raw.githubusercontent.com/hisah/dataset/master/Iris.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Develop model and export as pmml\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.feature import RFormula\n",
    "from pyspark.sql.session import SparkSession\n",
    "spark = SparkSession(sc)\n",
    "df = spark.read.csv(\"Iris.csv\", header = True, inferSchema = True)\n",
    "\n",
    "formula = RFormula(formula = \"Species ~ .\")\n",
    "classifier = DecisionTreeClassifier()\n",
    "pipeline = Pipeline(stages = [formula, classifier])\n",
    "pipelineModel = pipeline.fit(df)\n",
    "# Exporting the fitted example pipeline model to a PMML file:\n",
    "from pyspark2pmml import PMMLBuilder\n",
    "pmmlBuilder = PMMLBuilder(sc, df, pipelineModel).putOption(classifier, \"compact\", True)\n",
    "pmmlBuilder.buildFile(\"DecisionTreeIris.pmml\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"setupDataModel\"></a>\n",
    "\n",
    "## 1.3 Add data and model to your project\n",
    "\n",
    "The PMML model and the streaming data set need to be imported into the project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"create\"></a>\n",
    "\n",
    "# 2. Create the application\n",
    "\n",
    "\n",
    "All Streams applications start with  a `Topology` object, so we start by creating one.<br>Additionally we add our data set to the topology as a dependency, which means that is bundled within the built application and so available at the environment where the application will run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To Do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"defineInput\"></a>\n",
    "\n",
    "## 2.1 Define Data Input "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simulate an endless stream of data we will read the Iris data file repeatedly and submit each line in the file as a tuple. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"analyzeData\"></a>\n",
    "## 2.2 Analyze and score data\n",
    "Now that we have created a stream of data, we need to define the analytics we want to perform on our data. We want to use the PMML model to predict the Specie of each data instance on the input stream data. \n",
    "\n",
    "\n",
    "<a id=\"prepareData\"></a>\n",
    "### 2.2.1 Prepare data\n",
    "Before scoring there is the need to make sure that your data is in the format that the model expects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"scoreData\"></a>\n",
    "### 2.2.2 Score data\n",
    "Invoke the `pmml.score` function to the `preprocess` stream to score data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"defineOutput\"></a>\n",
    "## 2.3 Define Output\n",
    "\n",
    "The `score` stream is our final result.  We use `score.publish()` function to make this stream available to other applications. \n",
    "\n",
    "If you want to send the stream to another database or system, you would use a sink function (similar to the source function) and invoke it using e.g. `score.for_each`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"submit\"></a>\n",
    "\n",
    "# 3. Submit the application\n",
    "A running Streams application is called a *job*. This next cell submits the application for execution and prints the resulting job id.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The submission_result object contains information about the running application, or job\n",
    "print(\"Submitting Topology to Streams for execution..\")\n",
    "submission_result = submit_topology(topo)\n",
    "\n",
    "if submission_result.job:\n",
    "  streams_job = submission_result.job\n",
    "  print (\"JobId: \", streams_job.id , \"\\nJob name: \", streams_job.name)\n",
    "else:\n",
    "  print(\"Submission failed: \"   + str(submission_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"view\"></a>\n",
    "\n",
    "# 4. Use the `View` to access data from the job\n",
    "Now that the job is started, use the `View` object you created in step 2.3 to start retrieving data from a `Stream`.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Display the results in real time</b>  \n",
    "\n",
    "Calling `View.display()` from the notebook displays the results of the view in a table that is updated in real-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Display the results for 30 seconds\n",
    "score_view.display(duration=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> See job status </b>  \n",
    "\n",
    "You can view job status and logs by going to **My Instances** > **Jobs**. Find your job based on the id printed above.\n",
    "Retrieve job logs using the \"Download logs\" action from the job's context menu.\n",
    "\n",
    "To view other information about the job such as detailed metrics, access the graph. Go to **My Instances** > **Jobs**. Select \"View graph\" action for the running job.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"cancel\"></a>\n",
    "\n",
    "# 5. Cancel the job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell generates a widget you can use to cancel the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cancel the job in the IBM Streams service\n",
    "submission_result.cancel_job_button()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also interact with the job through the [Job](https://streamsxtopology.readthedocs.io/en/stable/streamsx.rest_primitives.html#streamsx.rest_primitives.Job) object returned from `submission_result.job`\n",
    "\n",
    "For example, use `job.cancel()` to cancel the running job directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "We started with a `Stream` called `records`, which contained the data we wanted to analyze. Next, we used functions in the `Stream` object to perform simple preprocessing before we scored the data with a ML model and produced the `score` stream.\n",
    "\n",
    "After submitting the application to the Streams service, we connected to the `score_view` view to see the results within the notebook."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
